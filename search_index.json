[["index.html", "Air-Health SWS R targets (Last edited on 2025-07-14) 1 Introduction", " Air-Health SWS R targets (Last edited on 2025-07-14) 1 Introduction This is an R targets pipeline for environmental health impact assessment using air pollution as a case study. Data is drawn from the Australian Bureau of Statistics (statistical area boundaries, population and mortality) and the Atmospheric Composition Analysis Group (Satellite-derived PM2.5). Instructions on how to get started with the code as provided is given in section Getting started with further details in Methods and Code guide. Known issues are detailed in Issues. A series of case studies developed by tweaking the initial pipeline is then described. The theoretical and epidemiological concepts underpinning health impact assessments in this context is then outlined in the sections Background and Epidemiological Concepts "],["getting-started.html", "2 Getting started 2.1 Initial setup and run-through", " 2 Getting started This R targets pipeline for environmental health impact assessment has been developed on R 4.1.2 “Bird Hippie” and RStudio 2021.09.2 “Ghost Orchid”. It requires R &gt;= 4.0.0 and access to the CARDAT platform’s Environment_General data storage folder on Nextcloud. The structure and syntax of an R targets pipeline may be unfamiliar to you depending on your level of coding experience. Depending on your intended usage, some or all of the following may guide your understanding of the workflow. Links to further useful examples and documentation are provided in the references. 2.1 Initial setup and run-through To run the Air Health SWS for the first time: Download and unzip or clone the air-health-sws-r-targets repository from the Code dropdown button. Load the R project. Open the _targets.R script. _targets.R script is where you customise the workflow to suit your study needs. Define global variables – line 21 Set your analysis year and states (location) to set the study coverage – note with the initial parameters in the pipeline, years are limited to 2010-2015. Set your directory pathway to CARDAT data Set the download_data boolean and dir_cardat to the correct path (parent directory of Environment_General). Line 86 – data extraction and derivation Provide counterfactual scenario(s) and calculate the delta Counterfactual being the alternative air pollution exposure level This can either be an absolute number (e.g. a guideline value such as the WHO guidelines) Or a derived value – e.g. the minimum value from monitoring data. Line 126 – Analysis Input risk estimate: Relative risk, including 95% confidence intervals, uses 1.062 (1.041, 1.084) is the default – as per WHO guidelines Open the main.R script. (This is not integral to the targets pipeline but is a place to keep all the useful commands for visualising, running and exploring the pipeline outside of the pipeline itself.) Begin running the script line-by-line from the top. renv should automatically install and activate. Install the packages using renv::restore() or try the alternative custom installation function install_pkgs() (installs the latest version of the library if it is not already available). This step may take some time. If you have set download_data &lt;- FALSE in _targets.R, uncomment and run the lines at the top of the Run pipeline section to authenticate your cloudstoR package’s access to Cloudstor. You should not need to authenticate again unless your credentials have changed. Continue to visualise and run the pipeline. See appendix A for known error codes and troubleshooting. See the results of the desired target with tar_read(target_name). "],["methods.html", "3 Methods", " 3 Methods Population data The R targets workflow uses age-specific population counts in 5-year age groups for each Statistical Area level 2 (SA2) geographical area (2016 ABS geographical boundaries), freely available from the Australian Bureau of Statistics dataset “Population by Age and Sex, Regions of Australia, Estimated Residential Population 2006–2016” from ABS-TableBuilder (cat. no. 3235.0). As the PM2.5 and mortality risk function applied is for persons age 30+, the population used analyses is limited to 5-year age groups from 30 - 35 up to 100+. Health data Mortality data by 5-year age groups from 30 years up to and including 100 years + is used, freely accessible from the Australian Bureau of Statistics (Cat. No. 3302.0 – Deaths, Australia, available from the ABS.Stat website). Baseline age-specific annual mortality rates are calculated for each year by linking the mortality data with age-specific populations. Exposure assessment Accurate and reliable exposure assessment is critical to the validity and generalization of environmental epidemiological studies. Errors in exposure assessment can lead to biased or inaccurate estimates of the association between exposure and health outcomes, potentially leading to erroneous conclusions about the health risks of environmental agents. Exposure assessment of PM2.5 can be challenging, as the pollutant is widespread and varies in concentration over time and space. The R targets workflow estimates population exposure to PM2.5 by obtaining annual average PM2.5 concentrations from a validated satellite-based land-use regression (LUR) model, as described in Knibbs et al. (2018). This model incorporates observed PM2.5 measurements from air-monitoring stations with satellite data, chemical-transport model simulations and land-use data to predict concentrations across the study region by ABS mesh-block (MB) spatial unit. Data are available upon request from the Australian Centre for Air pollution, energy, and health Research (CAR). Annual average PM2.5 concentrations are calculated for the centroids of Australian Bureau of Statistics (ABS) MBs from the 2011 census geography. MBs are then assigned to SA2s from 2016 to derive population-weighted average exposures. Attributable number Australia has a limited number of epidemiological studies of long-term exposure to PM2.5 and mortality, so attributable mortality was calculated by applying a relative risk (RR) function estimated from a meta-analysis of European and North American studies, as recommended by WHO (Hoek et al. 2013). A pooled RR of 1.062 (95% CI 1.041, 1.084) per 10-g/m3 increment in annual average PM2.5 exposures of people aged ≥30 years is recommended for health-impact assessments of PM2.5 (WHO 2013). That is, for every 10µg/m3 increase in the PM2.5 annual average exposure, the risk of death increases by 6.2% (95% CI 4.1, 8.4%). This RR was used to calculate the attributable numbers (AN) of deaths associated with PM2.5 exposure in each SA2. AN was calculated based on estimates of baseline PM2.5 compared to the counterfactual and then aggregated to the state using the following equation: \\[ AN = \\sum (1 - e^{(1 - \\beta \\Delta_{ij})}) \\times \\text{Expected}_{ij} \\] Where \\(Expected_{ij}\\) is the death count estimated by applying the mortality rate in age group \\(i\\) to age-specific population counts within SA2 \\(j\\), \\(\\beta = \\log(RR)/10\\), and \\(\\Delta X_{ij}\\) is the change in annual PM\\(_{2.5}\\) concentration from baseline concentrations to counterfactual concentrations in SA2 \\(j\\). Baseline concentrations were estimated as the population-weighted PM\\(_{2.5}\\) levels for each SA2 by year. Counterfactual exposure concentrations A counterfactual exposure concentration is a hypothetical exposure level that represents what would have happened if an individual or population had been exposed to a different level of an environmental agent than they actually were. It is a crucial concept in assessing the causal relationship between environmental exposures and health outcomes. An example of a counterfactual exposure value is the WHO PM2.5 annual average guideline value of 5µg/m3. An alternative scenario is using the MB with the lowest annual average PM2.5 value for the study region. References Hoek, Gerard, Ranjini M Krishnan, Rob Beelen, Annette Peters, Bart Ostro, Bert Brunekreef, and Joel D Kaufman. 2013. “Long-Term Air Pollution Exposure and Cardio- Respiratory Mortality: A Review.” Environmental Health 12 (1). https://doi.org/10.1186/1476-069x-12-43. Knibbs, Luke D., Aaron Van Donkelaar, Randall V. Martin, Matthew J. Bechle, Michael Brauer, David D. Cohen, Christine T. Cowie, et al. 2018. “Satellite-Based Land-Use Regression for Continental-Scale Long-Term Ambient PM 2.5 Exposure Assessment in Australia.” Environmental Science and Technology 52 (21): 12445–55. https://doi.org/10.1021/acs.est.8b02328. WHO. 2013. “Health Risks of Air Pollution in Europe – HRAPIE Project: Recommendations for Concentration–Response Functions for Cost–Benefit Analysis of Particulate Matter, Ozone and Nitrogen Dioxide.” World Health Organization, 65. https://doi.org/10.1021/acs.est.5b05833. "],["code-overview.html", "4 Code overview 4.1 R targets package 4.2 Directory and File Structure 4.3 _targets.R script 4.4 Metaprogramming", " 4 Code overview The structure and syntax of an R targets pipeline may be unfamiliar to you depending on your level of coding experience. Depending on your intended usage, some or all of the following may guide your understanding of the workflow. Links to further useful examples and documentation are provided. 4.1 R targets package The R targets package, a set of pipeline implementation and management tools, forms the basis of the Air health Scientific Workflow System. Using targets aids the reproducibility of analyses, tracking input data, parameters, code and dependencies to determine which steps need to be rerun when a change is detected. A targets pipeline is structured as a list of targets, each of which has a name and associated code block. The result of each target is saved and can be used in other targets by referring to it by name. On running the pipeline, each target is checked for changes to format, metadata and data, and is rerun if a change is detected. If there has been no change, the target is skipped (code is not run). Note that if a target changes, all dependent downstream targets will be run as the dependencies are recorded in target metadata. More complex pipelines can be set up with targets branching functionality and tarchetypes package. See the targets manual and documentation for further information. 4.1.1 Function-oriented programming Targets is designed to be function-oriented, writing and calling functions. This is in contrast to the style of programming that runs step-by-step, top to bottom. An example of the latter: x &lt;- 2 y &lt;- 3 z &lt;- x*y In targets: do_multiply &lt;- function(a, b){ a*b } list( tar_target(x, 2), tar_target(y, 3), tar_target(z, do_multiply(x, y)) ) While for this example, there seems to be little benefit from creating a function (indeed one could simply write tar_target(z, x*y)), it aids code clarity and efficiency for more complex workflows. Clearly named functions can self-describe their intended purpose, with defined inputs (arguments) and output(s) (return value). Carefully defined generalised functions may be reused as needed within or across projects. 4.2 Directory and File Structure The key files and folders of the Air Health SWS targets pipeline are as follows: ├── main.R ├── _targets.R ├── renv.lock ├── R/ ├──── func_analysis/ ├──── func_data/ ├──── func_helpers/ ├──── func_viz/ ├──── import_data/ ├──── pipelines/ ├── renv/ The main.R script is where you should start. It contains a few lines of code for restoring the packages, visualising the targets pipeline, running the pipeline and viewing target results. It does not make any changes to the workflow. Further exploratory analysis, outside of the pipeline, can be added here. The file renv.lock and folder renv/ are part of renv, a package management library. Opening the R project should automatically prompt renv to install and activate the project environment. Running renv::restore() will install required packages (as according to renv.lock). The _targets.R script forms the essential core of the targets pipeline, This is where the targets are defined, along with sourcing of required functions and specification of required libraries. See Section B.3 for more information. All custom functions are stored in the R/ folder. These are sourced near the top of the _targets.R script (and in main.R where needed). For clarity, the functions are arranged in a series of folders: func_analysis/: functions to analyse input data, acting on tidied and combined data func_data/: functions to combine and derive tidied input data to prepare for analysis func_helpers/: miscellaneous helper functions that are not directly concerned with the processing or analysis of data func_viz/: functions to visualise or output data import_data/: functions to create targets for the import and tidying of specific datasets pipelines/: examples of metaprogramming in targets package (not implemented) 4.3 _targets.R script As is standard with any _targets.R script, the structure is as follows: Load targets library (and tarchetypes if using) Source custom functions Set global variables Set target options (set what R packages are to be available to the pipeline) Define targets Custom functions used in the pipeline are loaded from the R/ folder. Though one can define the functions within _targets.R, keeping functions separately helps to keep code tidy. Additionally, the function files can be sourced or copied as needed for other projects. Global variables, here state and year, are a tidier way to specify parameters that are repeatedly used. In this case, the state and/or year are passed into various import data functions to indicate which subset of available data to use. The boolean download_data, to indicate whether to retrieve data from Cloudstor using the cloudstoR library, and data paths are also specified as global variables for ease of modification. Packages specified in tar_option_set are globally available to subsequent targets. If a target fails because a function cannot be found, double-check the required package is listed here. Finally, targets are defined in a list. For legibility, targets are divided into four lists, assigned to variables input, data, analysis and viz. These are then combined in the final list that defines the pipeline. Each of the target divisions has a corresponding function folder. input ....... R/import_data data ........ R/func_data analysis .... R/func_analysis viz ......... R/func_viz It is, of course, not necessary to use this organisation of targets and function files. All targets can be directly defined within the pipeline list and all function files can be stored under R/, or some alternative arrangement is possible. 4.3.1 input targets Each element in the input list is the result of calling a function to import and tidy a specific dataset. Unlike the subsequent target lists data, analysis, and viz where an element defines one target, the functions called in input generate a series of targets. The series of targets tracks the data file(s), reads and tidies the data. Since each data has its own formats and quirks, the tidying process is unique to each and thus the code block is defined in the command argument of the target rather than as a separate function. (See any one of the functions under R/import_data.) Note that some of the import functions use tar_target_raw to include outside parameters such as the state or year. Datasets are not combined or dependent on one another at this stage. Data is manipulated into a tidy format (e.g. standardised names, converting column data types, converting to long format), and may be subsetted to relevant columns if the dataset is large. Further processing of data, such as calculation, combination and extraction takes place in data list. 4.3.2 data targets The separate tidied datasets are combined and processed to a stage where the data is ready to be passed to an analysis function. In this pipeline, this covers the extraction of environmental exposure (from source rasters), calculation of counterfactual exposure, calculation of mortality rate in the impact population, application of mortality rate to the study population and aggregation of population-weighted exposure to study population regions. The end result of this section of targets is a data table of the study population with expected deaths (from application of mortality data) and exposure in baseline and counterfactual cases (from exposure rasters and defined counterfactual value). It is not necessary to gather all data into a single table, but avoids redundancy if you have several analysis targets working on the same data - you will not have to combine the data at the start of every analysis target. As a sidenote, it may be observed that some datasets are split over multiple files, for instance, the ABS meshblock files are by state. Depending on the dataset, tidying and processing may be best done file by file. This is possible through dynamic branching, where target B iterates over the output of other target(s) as defined by the pattern argument. Such dynamically-branched targets appear as a square with tar_glimpse or tar_visnetwork. (Read more at the targets manual) Consider the raster extraction to polygon step, one of the more time-consuming steps, where the inputs are exposure rasters (one file = one year) and ABS meshblock polygons (one file = one state). All the exposure rasters share the same projection, extent and resolution and thus can be stacked into a multi-layer raster - extracting a multi-layer raster does not cost much more than extracting from a single-layer raster. On the other hand, the cost of extraction is heavily dependent on the number and complexity of polygons. If an extra state were to be added to the pipeline, it would minimise cost to process and extract each set of state meshblocks separately via dynamic branching. Consequently, dynamic branching is used only on the ABS meshblocks dataset and not the exposure rasters, and branches recombined only after the extraction process is complete. 4.3.3 analysis targets After data processing, analysis is performed through two targets - one defining the health impact response and the other applying the response to the processed data to calculate the attributable number of deaths. Further targets can be added to determine other health measures such as years of life lost. 4.3.4 viz targets Naturally the results of analysis should be visualised in some form, at the very least for common-sense check. A target can be defined to produce a plot, or, if using tarchetypes, render an R Markdown report which can draw on output of other targets in its content. In the targets viz_an and leaflet_an, the code block no longer consists of a single function call. Instead, it is a series of data manipulation statements, aggregating and merging with spatial data, before calling the custom plot function. This structure keeps the plot function generalisable rather than specific to the data inputs. The data manipulation code can also be split off into a separation function or even a separate target if the results will be used in multiple targets. The R Markdown report is rendered in a target by specifying the appropriate .Rmd file in the tarchetypes::tar_render function. To minimise computation time and take advantage of the targets pipeline features, minimal processing should occur in R Markdown code. Target outputs are retrieved with tar_read or tar_load, Read more in the R targets manual - Literate Programming. 4.3.5 Pipeline list The _targets.R script must end with a list of targets defining the pipeline, hence all targets previously defined are included as nested lists in this final list. One more target is introduced here to ensure the existence of the data path (if not downloading data) or valid authentication of Cloudstor access (if downloading data). It is set to run first with the argument priority = 1. 4.4 Metaprogramming The R targets package includes metaprogramming tools (based on the rlang package), that is, tools using code to generate code. One of the simpler cases is static branching, generating a number of branched targets over a series of varying parameters, e.g. using different methods of analysis or modelling, or changing an input parameter to the modelling function. Full sets of targets (target factories) and full pipelines can also be generated on given parameters. These simplify the construction of a new targets pipeline, but is less customisable. See the stantargets package for an example of a target factory and [targets-shiny] for a fully-generated _targets.R script with Shiny interface built on top. An example of the pipeline-generating function resides in R/pipelines/write_pipeline_pm25_hia.R. Here the global variables in the original targets.R file are instead taken as arguments to the function. The targets pipeline code is written into the tar_helper function (which writes out to the _targets.R or other specified location). Variables (like states and years) are substituted into this code using the !! operator which forces the evaluation of the following expression. (There is also a !!! operator which both evaluates and unpacks, but it is not demonstrated here.) "],["issues.html", "5 Issues", " 5 Issues Requires many packages to be installed. Depending on your existing setup, it could take up to an hour to install everything Packages visNetwork and rgdal may need to be installed manually for all code to work Error: Error installing package &#39;ps&#39;: ============================== * installing to library &#39;C:/Users/djor8013/OneDrive - The University of Sydney (Staff)/En Health/air-health-sws-r-targets-main/renv/staging/1&#39; * installing *source* package &#39;ps&#39; ... ** package &#39;ps&#39; successfully unpacked and MD5 sums checked ** using staged installation Warning in system(&quot;sh ./configure.win&quot;) : &#39;sh&#39; not found ERROR: configuration failed for package &#39;ps&#39; * removing &#39;C:/Users/djor8013/OneDrive - The University of Sydney (Staff)/En Health/air-health-sws-r-targets-main/renv/staging/1/ps&#39; Error: install of package &#39;ps&#39; failed [error code 1] Solution: Uncomment out help download function: source(&quot;R/func_helpers/helper_install_pkgs.R&quot;) install_pkgs(repos = getOption(&quot;repos&quot;)) Error: ! Error running targets::tar_make() Target errors: targets::tar_meta(fields = error, complete_only = TRUE) Tips: https://books.ropensci.org/targets/debugging.html Last error: The download destination specified is likely used by a sync client. Please choose another destination. Solution: Create destination folder for CARDAT mirroring that is not a sync client (e.g. on local computer) Save _targets.R after doing this Error: ! Error running targets::tar_make() Target errors: targets::tar_meta(fields = error, complete_only = TRUE) Tips: https://books.ropensci.org/targets/debugging.html Last error: Failed to open file C:/Users/djor8013/OneDrive - The University of Sydney (Staff)/Desktop/air-health-sws-r-targets-main/data_provided/Environment_General/Air_pollution_model_ GlobalGWR_PM25/GlobalGWR_PM25_V4GL02/data_derived/ GlobalGWR_PM25_GL_201301_201312-RH35-NoNegs_AUS_20180618.tif.curltmp, Solution: File path name too long Shorten dir_cardat pathname in _targets.R For example: remove “OneDrive - The University of Sydney (Staff)” Error: ! Error running targets::tar_make() Target errors: targets::tar_meta(fields = error, complete_only = TRUE) Tips: https://books.ropensci.org/targets/debugging.html Last error: error in evaluating the argument &#39;x&#39; in selecting a method for function &#39;brick&#39;: Cannot create RasterLayer object from this file; perhaps you need to install rgdal first Solution: Install and load package rgdal Error: Error: ! Error running targets::tar_make() Target errors: targets::tar_meta(fields = error, complete_only = TRUE) Tips: https://books.ropensci.org/targets/debugging.html Last error: &#39;breaks&#39; are not unique Solution: Attributable number for some scenarios can be very small – colourQuantile in r script viz_leaflet_an cannot handle these small numbers, will have quantile cutoffs with same break numbers. Open viz_leaflet_an.R Change: pal1 &lt;- colorQuantile( palette = &quot;RdYlBu&quot;, domain = sf_an$attributable, n = 5, reverse = TRUE ) To: pal1 &lt;- colorNumeric( palette = &quot;RdYlBu&quot;, domain = sf_an$attributable ) This creates a continuous pallet rather than a categorical palette. "],["case-study---australian-nepm-standard.html", "6 Case Study - Australian NEPM standard", " 6 Case Study - Australian NEPM standard Estimate the mortality burden due to annual exposure to ambient fine particulate matter &lt;2.5 µg (PM2.5) above the current (8 µg) WHO annual PM2.5 guidelines in Western Australia during 2013-2014. Set Global variables – line 21 years &lt;- 2013:2014 states &lt;- c(\"WA\") Provide counterfactual scenario – line 104 In this use case, a scenario is an absolute number. However, it can be a derived value. Provide counterfactual scenario(s) and calculate delta abs = absolute value min = derives from state monitoring data tar_target( combined_exposures, do_env_counterfactual(data_env_exposure_pm25, &quot;abs&quot;, 8), pattern = map(data_env_exposure_pm25) ) Input relative risk estimate used for case scenario (default RR as defined by WHO guidelines) – line 128 RR input as c(RR, lower 95% CI bound, upper 95% CI bound) analysis &lt;- list( # construct a function given relative risks and theoretical minimum risk # the argument exposure_response_func takes a three element numeric vector, representing the relative risk, lower confidence interval and upper confidence interval (in that order) tar_target(health_impact_function, do_health_impact_function( case_definition = &#39;crd&#39;, exposure_response_func = c(1.062, 1.041, 1.084), theoretical_minimum_risk = 0 ) ) Run pipeline from Main.R Create an HIA report by running HIA 2013 2014 WA 8ug.Rmd "],["case-study---alternate-pm2.5-surfaces.html", "7 Case Study - Alternate PM2.5 surfaces", " 7 Case Study - Alternate PM2.5 surfaces The PM2.5 exposure surfaces used in the provided pipeline comes from Surface PM2.5 V4.GL.02 dataset developed by van Donkelaar, A. et al. (2016). Alternative models of PM2.5 differing in method, temporal or spatial coverage and/or resolution which are more suited to your particular study may be used as the input exposure rasters. To use different PM2.5 surfaces, replace the call to function import_globalgwr_pm25_2010_2015 in _targets.R with targets importing and tidying the new raster data. A satellite-derived land use regression (SatLUR) modelled PM2.5 surface produced by Luke Knibbs is available on request. The preparation of van Donkelaar’s PM2.5 surfaces is performed in targets infile_globalgwr_pm25_2010_2015_files, infile_globalgwr_pm25_2010_2015 and tidy_env_exposure_pm25. (Only the latter two are present if downloading the data.) The first two targets are automatically generated by the tarchetypes::tar_files_input then tidied and gathered into a raster brick in tidy_env_exposure_pm25. This is performed in the following few lines: inputs &lt;- list( ..., # exposure rasters exposure = import_globalgwr_pm25_2010_2015(years, download = download_data, datadir_envgen = file.path(dir_cardat, dir_envgen)), ... ) Substitute in a tar_files_input pointing to the new input exposure raster files. Read and tidy the data in a tar_target, producing a RasterBrick (or stack) with named layers by year. Your code should look similar to the following. inputs &lt;- list( ..., # exposure rasters exposure = list( tar_files_input( infile_pm25, file.path( sprintf(&quot;YOUR_DATA_DIR/SatPM25_2000_2015/data_derived_rasters/satlur_pm25_ug_m3_%s.tif&quot;, years) ) ), tar_target( tidy_env_exposure_pm25, { b &lt;- brick(stack(infile_pm25)) # rename the layers of the RasterBrick with the year names(b) &lt;- years return(b) } ) ), ... ) Add additional processing steps in tidy_env_exposure_pm25 as needed to tidy the raster input. "],["case-study---who-recommended-target-guidelines.html", "8 Case Study - WHO recommended target guidelines", " 8 Case Study - WHO recommended target guidelines The provided pipeline uses a relative risk of 1.06 per 10 µg/m3, with lower and upper confidence intervals (lci, uci) 1.02 and 1.08 respectively. The counterfactual is set as the minimum PM2.5 by state. Updated WHO 2021 recommendations specify a target for annual PM2.5 of 5 µg/m3. Interim targets are set at 35, 25, 15 and 10 µg/m3. The review which contributed to the setting of these target PM2.5 levels used a hazard ratio of 1.08 per 10 µg/m3. To explore the counterfactual scenario as described by the WHO recommended target, the calculation of counterfactual scenario and the health impact function must be modified. Counterfactual scenario The counterfactual exposure is calculated in the R target combined_exposures, The function call to do_env_counterfactual can be replaced with a block of code that adds the counterfactual exposure and delta to the output of target data_env_exposure_pm25. However, the do_env_counterfactual already includes functionality to add these columns based on an absolute value rather than using the minimum exposure by state. To use a counterfactual scenario based on the WHO’s recommended target of 5 µg/m3, alter the cf_mode argument from \"min\" to \"abs\", indicating the counterfactual is an absolute value. Provide a third argument cf_value as a numeric set to the WHO recommendation, 5. Your code will look similar to the following, in place of the combined_exposures target: ... # Provide counterfactual scenario and calculate delta tar_target( combined_exposures, do_env_counterfactual(data_env_exposure_pm25, &quot;abs&quot;, 5), pattern = map(data_env_exposure_pm25), ), ... Health impact response Next, modify the R target health_impact_function which returns a function to calculate the attributable number. In the do_health_impact_function, the argument exposure_response_func takes a three element numeric vector, representing the relative risk, lower confidence interval and upper confidence interval (in that order). Change the relative risk to that used by WHO, 1.08. If no confidence intervals are available, they may be set to NA. Your code should look similar to the following: ... tar_target(health_impact_function, do_health_impact_function( case_definition = &#39;crd&#39;, exposure_response_func = c(1.08, NA, NA), theoretical_minimum_risk = 0 ) ), ... "],["case-study---alternate-pollutant.html", "9 Case Study - Alternate Pollutant", " 9 Case Study - Alternate Pollutant The pipeline can be modified and extended to process and assess the impact of alternate pollutants or mixed-pollutant effects. You will need a set of suitable exposure rasters of your pollutant(s) of interest. A satellite-derived land use regression (SatLUR) modelled NO2 surface produced by Luke Knibbs is available on request. Exposure input New sets of pollutant rasters should be read and tidied in targets, similar to the code described in Case Study - Alternate PM2.5 surfaces. Give the targets unique appropriate names. For each pollutant, the tidied RasterBrick/RasterStack should be passed to the do_env_exposure to extract mean exposure at the meshblock level. The calculation of the counterfactual scenario follows (target combined_exposures in the initial pipeline) - either use the do_env_counterfactual function, or write your own custom code to calculate or read in a counterfactual. To ensure the pipeline does not rerun code needlessly, keep the processing of each pollutant in separate targets unless it is necessary or more efficient to process multiple pollutants at once. Consider a pipeline analysing both PM2.5 and NO2: if the source of NO2 data changes, only the NO2 exposure need be extracted, thus this target should be separate from the PM2.5 extraction step. Health Impact You will most likely need to alter the do_health_impact_function or develop your own function to calculate attributable number (or other measure of health impact). Elements to consider include: Health impact of interest Relative risk and what unit change it is based on Theoretical minimum risk (if applicable) Multi-pollutant effects "],["background.html", "10 Background", " 10 Background Health Impact Assessment (HIA) of ambient air pollution can quantify the impacts on human health using current and historical air pollution data and point directions for sustainable transitions that could promote policies, programmes, or projects to reduce air population. HIAs can be used to make recommendations for decision-makers and stakeholders, aiming to maximise a proposal’s positive health effects and minimise its negative effects (WHO 2013). A HIA also provides a way to engage with the public sphere by producing meaningful numbers to quantify the health effects of air pollution. The Scientific Workflow System (SWS) R targets workflow is a tool for quantifying the impact on health for given air pollution policy intervention scenarios, illustrated by a WHO guideline case study. Further background information on the Epidemiological concepts underpinning HIAs and the methods utilised in this workflow can be found in Appendix B. References WHO. 2013. “Health Risks of Air Pollution in Europe – HRAPIE Project: Recommendations for Concentration–Response Functions for Cost–Benefit Analysis of Particulate Matter, Ozone and Nitrogen Dioxide.” World Health Organization, 65. https://doi.org/10.1021/acs.est.5b05833. "],["epi-concepts.html", "11 Epidemiological concepts 11.1 Epidemiological study designs 11.2 Relative risk, odds ratio and hazard ratio", " 11 Epidemiological concepts We have presented additional information about various concepts underpinning epidemiological study design that you may find helpful in understanding health impact assessment methodology. 11.1 Epidemiological study designs Source and sample populations One of the fundamental concepts underpinning all epidemiological research is the requirement to clearly define the study base or the source population (Checkoway, Pearce, and Kriebel 2007). The source population is the entire group of individuals or objects with a common characteristic or condition that interests the study. This may include all individuals living in a particular geographical area, all individuals of a particular age group, or all individuals with a specific disease or health condition. The source population is the starting point for identifying potential study participants or units. On the other hand, a sample population is a subset of the source population selected for inclusion in the study. The sample population is usually selected through a sampling process that aims to ensure that the sample is representative of the source population in terms of the characteristics or conditions of interest. (Sharma 2011) Case definition In epidemiology, a case definition is a set of standard criteria used to identify whether an individual has a particular disease or health condition of interest. The case definition usually includes specific clinical, laboratory, or other diagnostic criteria that are used to classify an individual as a case or non-case. (Sharma 2011) A case definition aims to ensure that all cases are identified consistently and accurately across different settings and by other investigators. This is critical in epidemiological studies, as the case definition’s accuracy can affect the study findings’ validity and reliability. Mortality Mortality is a special type of incidence in epidemiology because it represents the ultimate outcome of disease or health conditions. While incidence refers to the number of new cases of a disease or health condition that occur in a population over a specified period, mortality refers to the number of deaths that occur in a population over the same period. In epidemiology, incidence and mortality are important measures of disease burden, but they provide different types of information. Incidence data provides information about the number of people newly diagnosed with a disease or health condition. In contrast, mortality data includes information about the number of people who die because of a disease or health condition. 11.2 Relative risk, odds ratio and hazard ratio Relative Risk Relative risk (RR) measures the strength of association between exposure to a risk factor and the occurrence of an outcome. It is calculated by dividing the incidence rate of the outcome in the exposed group by the incidence rate of the outcome in the unexposed group. An RR of 1 indicates that there is no association between exposure and outcome, an RR greater than 1 indicates a positive association (i.e., the exposed group has a higher risk of experiencing the outcome), and an RR less than 1 indicates a negative association (i.e., the exposed group has a lower risk of experiencing the outcome) (Viera 2008). In air pollution studies, RR is expressed as the ratio by which the risk of mortality increases per given increase in air pollution level. RR for a unit change in pollution level is represented by the coefficient β derived from empirical studies. For example, the WHO case study example uses a β coefficient from a pooled RR estimated from a meta-analysis of European and North American studies, as recommended by WHO. That is a RR of 1.062 (95% CI 1.041, 1.084) per 10-g/m3 increment in annual average PM2.5 exposures of people aged ≥30 years (WHO 2013). RR is a function of the difference in pollution levels \\((x_1 – x_0)\\). For any change in pollution level from \\((x_1 – x_0)\\), the relative risk is given by the formula: \\[ RR(x_1 - x_0) = \\exp(\\beta(x_1 - x_0)) \\] The pollution level \\(x_1\\) may be a target or cutoff level for which a policy or legislation aims, and it is likely to be lower than \\(x_0\\). Odds Ratio The odds ratio expresses the measure of the association between exposure and outcome, often used in case-control studies. It is calculated by dividing the odds of exposure in cases by the odds of exposure in controls. An OR of 1 indicates no association, an OR greater than 1 indicates a positive association and an OR less than 1 indicates a negative association (Viera 2008) Relative risk and odds ratio assume that the exposure precedes the outcome, but they differ in how they account for temporality. Relative risk is calculated using incidence rates, which require follow-up time, and therefore assumes a temporal relationship between exposure and outcome. On the other hand, the odds ratio does not require follow-up time and therefore does not directly account for temporality (Viera 2008). However, careful study design and analysis can still establish the temporal relationship between exposure and outcome Hazard Ratio Hazard ratios (HR) measure the strength of association between an exposure and a time-to-event outcome, such as the onset of a disease or death. Hazard ratios are commonly used in epidemiology and survival analysis to compare the risk of an outcome between two or more groups while accounting for differences in follow-up time. This is important because the time at risk for an event may differ between the two groups due to differences in the onset of exposure, the time of diagnosis, or the study duration. By accounting for differences in follow-up time, hazard ratios can provide a more accurate estimate of the risk of the outcome associated with the exposure. Within the context of air pollution epidemiological studies, a hazard ratio (HR) is the ratio of hazard rates corresponding to the conditions characterised by two distinct air pollution levels. The hazard rate (H) at pollution level \\(x_1\\) is derived from those at level \\(x_0\\) by: \\[ H(x_1) = RR(x_1 - x_0) \\times h(x_0) \\] The PAF (population attributable fraction) Population attributable fraction (PAF) estimates the proportion of disease or adverse health outcomes in a population that can be attributed to a specific risk factor or exposure. PAF is calculated by comparing the incidence of the disease or outcome in the total population to the incidence that would be expected if the population were not exposed to the risk factor or exposure of interest. The difference between these two incidences represents the proportion of cases attributable to the exposure (Health and Welfare 2015). Mathematically, PAF can be expressed as: \\[ PAF = \\frac{P_e \\times (RR - 1)}{1 + P_e \\times (RR - 1)} \\] Where: \\(P_e\\) = proportion of the population exposed to the risk factor or exposure \\(RR\\) = relative risk (or hazard ratio) associated with the exposure PAF can be interpreted as the proportion of cases that would be prevented if the exposure was eliminated from the population. A PAF of 0% indicates that the exposure is not associated with the disease or outcome, while a PAF of 100% indicates that all cases of the disease or outcome in the population can be attributed to the exposure. TMREL – Theoretical minimum risk exposure level The theoretical minimum risk exposure level (TMREL) is the level of exposure to a pollutant below which no adverse health effects are expected to occur. It is often used in air pollution epidemiology to inform regulatory decision-making and to set air quality standards. The TMREL is based on a risk assessment of the available evidence on the health effects of exposure to the pollutant of interest. The TMREL is typically set at a level well below the lowest level of exposure associated with adverse health effects in the available studies. Setting a TMREL involves balancing the need to protect public health and avoid unnecessary economic or social costs associated with reducing pollution levels. The TMREL can be influenced by various factors, including the nature and severity of the health effects associated with exposure, the size and characteristics of the exposed population, and the feasibility and costs of reducing exposure levels. References Checkoway, H., N. Pearce, and D. Kriebel. 2007. “Selecting Appropriate Study Designs to Address Specific Research Questions in Occupational Epidemiology.” Occupational and Environmental Medicine 64 (9): 633–38. https://doi.org/10.1136/oem.2006.029967. Health and Welfare, Australian Institute of. 2015. “Australian Burden of Disease Study 2015: Interactive Data on Disease Burden.” Canberra: AIHW. https://www.aihw.gov.au/reports/burden-of-disease/interactive-data-risk-factor-burden/contents/overview. Sharma, Sushil K. 2011. “Importance of Case Definition in Epidemiological Studies.” Neuroepidemiology 37 (2): 141–42. https://doi.org/10.1159/000332609. Viera, Anthony J. 2008. “Odds Ratios and Risk Ratios: What’s the Difference and Why Does It Matter?” Southern Medical Journal 101 (7): 730–34. https://doi.org/10.1097/smj.0b013e31817a7ee4. WHO. 2013. “Health Risks of Air Pollution in Europe – HRAPIE Project: Recommendations for Concentration–Response Functions for Cost–Benefit Analysis of Particulate Matter, Ozone and Nitrogen Dioxide.” World Health Organization, 65. https://doi.org/10.1021/acs.est.5b05833. "],["references.html", "References", " References Checkoway, H., N. Pearce, and D. Kriebel. 2007. “Selecting Appropriate Study Designs to Address Specific Research Questions in Occupational Epidemiology.” Occupational and Environmental Medicine 64 (9): 633–38. https://doi.org/10.1136/oem.2006.029967. Health and Welfare, Australian Institute of. 2015. “Australian Burden of Disease Study 2015: Interactive Data on Disease Burden.” Canberra: AIHW. https://www.aihw.gov.au/reports/burden-of-disease/interactive-data-risk-factor-burden/contents/overview. Hoek, Gerard, Ranjini M Krishnan, Rob Beelen, Annette Peters, Bart Ostro, Bert Brunekreef, and Joel D Kaufman. 2013. “Long-Term Air Pollution Exposure and Cardio- Respiratory Mortality: A Review.” Environmental Health 12 (1). https://doi.org/10.1186/1476-069x-12-43. Knibbs, Luke D., Aaron Van Donkelaar, Randall V. Martin, Matthew J. Bechle, Michael Brauer, David D. Cohen, Christine T. Cowie, et al. 2018. “Satellite-Based Land-Use Regression for Continental-Scale Long-Term Ambient PM 2.5 Exposure Assessment in Australia.” Environmental Science and Technology 52 (21): 12445–55. https://doi.org/10.1021/acs.est.8b02328. Sharma, Sushil K. 2011. “Importance of Case Definition in Epidemiological Studies.” Neuroepidemiology 37 (2): 141–42. https://doi.org/10.1159/000332609. Viera, Anthony J. 2008. “Odds Ratios and Risk Ratios: What’s the Difference and Why Does It Matter?” Southern Medical Journal 101 (7): 730–34. https://doi.org/10.1097/smj.0b013e31817a7ee4. WHO. 2013. “Health Risks of Air Pollution in Europe – HRAPIE Project: Recommendations for Concentration–Response Functions for Cost–Benefit Analysis of Particulate Matter, Ozone and Nitrogen Dioxide.” World Health Organization, 65. https://doi.org/10.1021/acs.est.5b05833. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
